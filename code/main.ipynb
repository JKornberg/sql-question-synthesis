{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mnt/c/src/school/anlp/hw3/ERIQG/code/evaluation.py\", line 18, in <module>\n",
      "    from rouge_score import rouge_scorer\n",
      "ModuleNotFoundError: No module named 'rouge_score'\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python evaluation.py --batch_size=16 --teacher_forcing_fraction 0.0 --resume eriqg_best.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/src/school/anlp/hw3/ERIQG/code/main.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/src/school/anlp/hw3/ERIQG/code/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/src/school/anlp/hw3/ERIQG/code/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../glove/usedwordemb.npy\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m inf:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/src/school/anlp/hw3/ERIQG/code/main.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     word_emb \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(inf)\n",
      "File \u001b[0;32m~/miniconda3/envs/anlp/lib/python3.9/site-packages/numpy/lib/npyio.py:434\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    432\u001b[0m _ZIP_SUFFIX \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPK\u001b[39m\u001b[39m\\x05\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    433\u001b[0m N \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 434\u001b[0m magic \u001b[39m=\u001b[39m fid\u001b[39m.\u001b[39;49mread(N)\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m magic:\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo data left in file\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/anlp/lib/python3.9/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open('../glove/usedwordemb.npy') as inf:\n",
    "    word_emb = np.load(inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][49/1762]\tEit 50  lr 0.001  KL Loss 0.0276 (0.1687)  CE Loss 4.9965 (6.5005)  C-BLEU 0.0595 (0.0197)\tTime 1.214 (0.000)\tData 0.007 (0.000)\t\n",
      "Epoch: [0][99/1762]\tEit 100  lr 0.001  KL Loss 0.0126 (0.0921)  CE Loss 4.5245 (5.5420)  C-BLEU 0.0776 (0.0416)\tTime 1.189 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][149/1762]\tEit 150  lr 0.001  KL Loss 0.0160 (0.0665)  CE Loss 3.7872 (5.0659)  C-BLEU 0.0846 (0.0497)\tTime 1.193 (0.000)\tData 0.009 (0.000)\t\n",
      "Epoch: [0][199/1762]\tEit 200  lr 0.001  KL Loss 0.0134 (0.0542)  CE Loss 2.3863 (4.5560)  C-BLEU 0.0823 (0.0592)\tTime 1.153 (0.000)\tData 0.007 (0.000)\t\n",
      "Epoch: [0][249/1762]\tEit 250  lr 0.001  KL Loss 0.0073 (0.0456)  CE Loss 1.9956 (4.0790)  C-BLEU 0.1579 (0.0743)\tTime 1.168 (0.000)\tData 0.007 (0.000)\t\n",
      "Epoch: [0][299/1762]\tEit 300  lr 0.001  KL Loss 0.0075 (0.0393)  CE Loss 1.9164 (3.7117)  C-BLEU 0.1678 (0.0894)\tTime 1.181 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][349/1762]\tEit 350  lr 0.001  KL Loss 0.0059 (0.0347)  CE Loss 1.6223 (3.4337)  C-BLEU 0.2382 (0.1037)\tTime 1.224 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][399/1762]\tEit 400  lr 0.001  KL Loss 0.0057 (0.0312)  CE Loss 1.7158 (3.2124)  C-BLEU 0.2174 (0.1166)\tTime 1.168 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][449/1762]\tEit 450  lr 0.001  KL Loss 0.0051 (0.0283)  CE Loss 1.4954 (3.0299)  C-BLEU 0.2657 (0.1298)\tTime 1.182 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][499/1762]\tEit 500  lr 0.001  KL Loss 0.0050 (0.0260)  CE Loss 1.3560 (2.8773)  C-BLEU 0.2782 (0.1416)\tTime 1.169 (0.000)\tData 0.005 (0.000)\t\n",
      "Epoch: [0][549/1762]\tEit 550  lr 0.001  KL Loss 0.0084 (0.0243)  CE Loss 1.4874 (2.7545)  C-BLEU 0.2085 (0.1513)\tTime 1.222 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][599/1762]\tEit 600  lr 0.001  KL Loss 0.0044 (0.0228)  CE Loss 1.5969 (2.6486)  C-BLEU 0.2258 (0.1601)\tTime 1.156 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][649/1762]\tEit 650  lr 0.001  KL Loss 0.0054 (0.0214)  CE Loss 1.8591 (2.5568)  C-BLEU 0.1986 (0.1681)\tTime 1.232 (0.000)\tData 0.012 (0.000)\t\n",
      "Epoch: [0][699/1762]\tEit 700  lr 0.001  KL Loss 0.0055 (0.0202)  CE Loss 1.4965 (2.4725)  C-BLEU 0.2625 (0.1758)\tTime 1.218 (0.000)\tData 0.010 (0.000)\t\n",
      "Epoch: [0][749/1762]\tEit 750  lr 0.001  KL Loss 0.0044 (0.0192)  CE Loss 1.3039 (2.4004)  C-BLEU 0.3043 (0.1828)\tTime 1.207 (0.000)\tData 0.009 (0.000)\t\n",
      "Epoch: [0][799/1762]\tEit 800  lr 0.001  KL Loss 0.0041 (0.0183)  CE Loss 1.3161 (2.3316)  C-BLEU 0.2475 (0.1895)\tTime 1.184 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][849/1762]\tEit 850  lr 0.001  KL Loss 0.0044 (0.0174)  CE Loss 1.3948 (2.2699)  C-BLEU 0.2881 (0.1958)\tTime 1.238 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][899/1762]\tEit 900  lr 0.001  KL Loss 0.0038 (0.0167)  CE Loss 1.4698 (2.2149)  C-BLEU 0.3113 (0.2014)\tTime 1.171 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][949/1762]\tEit 950  lr 0.001  KL Loss 0.0044 (0.0160)  CE Loss 1.2675 (2.1631)  C-BLEU 0.3235 (0.2074)\tTime 1.164 (0.000)\tData 0.011 (0.000)\t\n",
      "Epoch: [0][999/1762]\tEit 1000  lr 0.001  KL Loss 0.0037 (0.0154)  CE Loss 1.2252 (2.1171)  C-BLEU 0.3066 (0.2127)\tTime 1.202 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1049/1762]\tEit 1050  lr 0.001  KL Loss 0.0037 (0.0149)  CE Loss 1.1315 (2.0737)  C-BLEU 0.3190 (0.2182)\tTime 1.201 (0.000)\tData 0.007 (0.000)\t\n",
      "Epoch: [0][1099/1762]\tEit 1100  lr 0.001  KL Loss 0.0033 (0.0144)  CE Loss 1.1652 (2.0332)  C-BLEU 0.3373 (0.2231)\tTime 1.188 (0.000)\tData 0.009 (0.000)\t\n",
      "Epoch: [0][1149/1762]\tEit 1150  lr 0.001  KL Loss 0.0032 (0.0139)  CE Loss 1.2671 (1.9957)  C-BLEU 0.3687 (0.2278)\tTime 1.196 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1199/1762]\tEit 1200  lr 0.001  KL Loss 0.0029 (0.0135)  CE Loss 0.9913 (1.9601)  C-BLEU 0.3826 (0.2323)\tTime 1.185 (0.000)\tData 0.007 (0.000)\t\n",
      "Epoch: [0][1249/1762]\tEit 1250  lr 0.001  KL Loss 0.0034 (0.0131)  CE Loss 1.0984 (1.9279)  C-BLEU 0.3091 (0.2364)\tTime 1.195 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1299/1762]\tEit 1300  lr 0.001  KL Loss 0.0027 (0.0127)  CE Loss 1.0087 (1.8957)  C-BLEU 0.3770 (0.2405)\tTime 1.174 (0.000)\tData 0.009 (0.000)\t\n",
      "Epoch: [0][1349/1762]\tEit 1350  lr 0.001  KL Loss 0.0030 (0.0123)  CE Loss 1.2279 (1.8673)  C-BLEU 0.3150 (0.2444)\tTime 1.199 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1399/1762]\tEit 1400  lr 0.001  KL Loss 0.0030 (0.0120)  CE Loss 0.9555 (1.8397)  C-BLEU 0.3797 (0.2478)\tTime 1.181 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1449/1762]\tEit 1450  lr 0.001  KL Loss 0.0034 (0.0117)  CE Loss 1.3532 (1.8156)  C-BLEU 0.3144 (0.2508)\tTime 1.206 (0.000)\tData 0.009 (0.000)\t\n",
      "Epoch: [0][1499/1762]\tEit 1500  lr 0.001  KL Loss 0.0034 (0.0114)  CE Loss 0.8692 (1.7920)  C-BLEU 0.4214 (0.2536)\tTime 1.172 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1549/1762]\tEit 1550  lr 0.001  KL Loss 0.0037 (0.0112)  CE Loss 1.3969 (1.7690)  C-BLEU 0.2778 (0.2563)\tTime 1.255 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1599/1762]\tEit 1600  lr 0.001  KL Loss 0.0038 (0.0109)  CE Loss 1.1099 (1.7462)  C-BLEU 0.2846 (0.2592)\tTime 1.184 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1649/1762]\tEit 1650  lr 0.001  KL Loss 0.0042 (0.0107)  CE Loss 1.0370 (1.7253)  C-BLEU 0.3369 (0.2618)\tTime 1.174 (0.000)\tData 0.008 (0.000)\t\n",
      "Epoch: [0][1699/1762]\tEit 1700  lr 0.001  KL Loss 0.0030 (0.0105)  CE Loss 1.0384 (1.7049)  C-BLEU 0.3530 (0.2645)\tTime 1.175 (0.000)\tData 0.008 (0.000)\t\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python train.py --batch_size=32 --teacher_forcing_fraction 1.0 --prefix 'eriqg'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
